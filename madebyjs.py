import streamlit as st
import os
import json
import itertools
import base64
import tempfile
import platform 
import time
from datetime import datetime
import pandas as pd
from io import BytesIO
import gc


# [í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬]
from pdf2image import convert_from_path
from sentence_transformers import CrossEncoder 
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI, HarmBlockThreshold, HarmCategory
from langchain_community.retrievers import BM25Retriever
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage

# ==========================================================
# [0] ê¸°ë³¸ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# ==========================================================
st.set_page_config(page_title="ê±´ì„¤ CM AI í†µí•© ì†”ë£¨ì…˜ (Deep RAG)", page_icon="ğŸ—ï¸", layout="wide")

# 1. API í‚¤ ê°€ì ¸ì˜¤ê¸°
if "GOOGLE_API_KEY" in st.secrets:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
elif "GOOGLE_API_KEY" in os.environ:
    GOOGLE_API_KEY = os.environ["GOOGLE_API_KEY"]
else:
    st.error("ğŸš¨ ì¹˜ëª…ì  ì˜¤ë¥˜: Google API Keyê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY

# 2. Poppler ê²½ë¡œ (Windows í™˜ê²½ ëŒ€ì‘)
system_name = platform.system()
if system_name == "Windows":
    # ë¡œì»¬(ë‚´ ì»´í“¨í„°)ì—ì„œ ëŒë¦´ ë•Œë§Œ ê²½ë¡œ ì§€ì • (ë³¸ì¸ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”)
    # ì˜ ëª¨ë¥´ê² ìœ¼ë©´ ì¼ë‹¨ Noneìœ¼ë¡œ ë‘ì„¸ìš”. (í™˜ê²½ë³€ìˆ˜ì— ìˆë‹¤ë©´ ì‘ë™í•¨)
    POPPLER_PATH = None 
else:
    # Streamlit Cloud ë“± ì„œë²„(Linux)ì—ì„œëŠ” ë³´í†µ ê²½ë¡œ ì§€ì • ë¶ˆí•„ìš” (íŒ¨í‚¤ì§€ë¡œ ì„¤ì¹˜ë¨)
    POPPLER_PATH = None

# 3. ë°ì´í„° ê²½ë¡œ
DB_PATH_1 = "./chroma_db_part1"
DB_PATH_2 = "./chroma_db_part2"
JSON_DATA_PATH = "./legal_data_total_vlm.json"
RAW_DATA = []
# 5. íˆìŠ¤í† ë¦¬ íŒŒì¼ ê²½ë¡œ ì„¤ì •
HISTORY_FILE = "chat_history.json"

def save_chat_history():
    """ëŒ€í™” ë‚´ì—­ ì €ì¥ ì‹œ ì—‘ì…€ ë“± ë¬´ê±°ìš´ ë°ì´í„°ëŠ” ì œì™¸í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì €ì¥"""
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        serializable_msgs = []
        for m in st.session_state.messages:
            # ë©”ì‹œì§€ê°€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¼ ë•Œ (AI ë‹µë³€ ë“±)
            if isinstance(m, dict):
                # ì—‘ì…€ ë°ì´í„°(excel_data)ëŠ” ë¹¼ê³  roleê³¼ contentë§Œ ì¶”ì¶œ
                clean_msg = {
                    "role": m.get("role", "assistant"),
                    "content": m.get("content", "")
                }
            else:
                # ë©”ì‹œì§€ê°€ ê°ì²´ í˜•íƒœì¼ ë•Œ (ì‚¬ìš©ì ì§ˆë¬¸ ë“±)
                role = "user" if "Human" in str(type(m)) else "assistant"
                clean_msg = {
                    "role": role, 
                    "content": getattr(m, 'content', str(m))
                }
            
            serializable_msgs.append(clean_msg)
            
        # í…ìŠ¤íŠ¸ë§Œ ëª¨ì¸ ë¦¬ìŠ¤íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        json.dump(serializable_msgs, f, ensure_ascii=False, indent=4)

def load_chat_history():
    """ì €ì¥ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return []
    return []

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ìˆ˜ì • ---
if "messages" not in st.session_state:
    st.session_state.messages = load_chat_history() # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  íŒŒì¼ ë¡œë“œ
# 4. ëª¨ë¸ ì„¤ì •
MODEL_NAME = "models/gemini-2.5-pro" 

# ==========================================================
# [1] ì‹œìŠ¤í…œ ë¡œë”© (ê²€ìƒ‰ ì—”ì§„ & ëª¨ë¸)
# ==========================================================
class SimpleHybridRetriever:
    """BM25(í‚¤ì›Œë“œ) + Chroma(ë²¡í„°) ê²°í•© ê²€ìƒ‰ê¸°"""
    def __init__(self, bm25, chroma1, chroma2, raw_data):
        self.bm25 = bm25
        self.chroma1 = chroma1
        self.chroma2 = chroma2
        self.raw_data = raw_data
        
    def invoke(self, query):
        # 1. ë³‘ë ¬ ê²€ìƒ‰ ìˆ˜í–‰
        docs_bm25 = self.bm25.invoke(query)
        docs_c1 = self.chroma1.invoke(query)
        docs_c2 = self.chroma2.invoke(query)
        
        # 2. Chroma ê²°ê³¼ ë³µì› (ì¸ë±ìŠ¤ -> ì›ë³¸ í…ìŠ¤íŠ¸)
        real_docs_chroma = []
        for doc in (docs_c1 + docs_c2):
            try:
                idx = int(doc.page_content) 
                original_item = self.raw_data[idx] 
                content = original_item.get('content', '').strip()
                source = original_item.get('source', '').strip()
                article = original_item.get('article', '').strip()
                full_text = f"[{source}] {content}"
                new_doc = Document(page_content=full_text, metadata={"source": source, "article": article})
                real_docs_chroma.append(new_doc)
            except:
                continue

        # 3. ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°
        combined = []
        seen_ids = set()
        for d in itertools.chain(docs_bm25, real_docs_chroma):
            key = d.page_content[:30] # ë‚´ìš© ì•ë¶€ë¶„ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬
            if key not in seen_ids:
                combined.append(d)
                seen_ids.add(key)
        return combined[:200] # 1ì°¨ì ìœ¼ë¡œ ë„‰ë„‰í•˜ê²Œ ë°˜í™˜

@st.cache_resource
def load_search_system():
    global RAW_DATA
    if not os.path.exists(JSON_DATA_PATH):
        st.error("âŒ JSON ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
        
    with open(JSON_DATA_PATH, 'r', encoding='utf-8') as f:
        RAW_DATA = json.load(f)

    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=GOOGLE_API_KEY)
    
    if not os.path.exists(DB_PATH_1) or not os.path.exists(DB_PATH_2):
        st.error("âŒ DB í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    store1 = Chroma(persist_directory=DB_PATH_1, embedding_function=embeddings, collection_name="construction_laws")
    retriever1 = store1.as_retriever(search_kwargs={"k": 100})
    store2 = Chroma(persist_directory=DB_PATH_2, embedding_function=embeddings, collection_name="construction_laws")
    retriever2 = store2.as_retriever(search_kwargs={"k": 100})

    docs = []
    for item in RAW_DATA:
        content = item.get('content', '').strip()
        source = item.get('source', '').strip()
        if not content: continue
        doc = Document(page_content=f"[{source}] {content}", metadata={"source": source, "article": item.get('article', '')})
        docs.append(doc)
    
    bm25_retriever = BM25Retriever.from_documents(docs)
    bm25_retriever.k = 150
    hybrid_retriever = SimpleHybridRetriever(bm25_retriever, retriever1, retriever2, RAW_DATA)
    
    # --- [ìˆ˜ì • êµ¬ê°„] Cross-Encoder (Reranker) ë©”ëª¨ë¦¬ ìµœì í™” ë¡œë“œ ---
    try:
        reranker = CrossEncoder(
            "cross-encoder/ms-marco-TinyBERT-L-2-v2", 
            device="cpu", # ë¬´ë£Œ ì„œë²„ëŠ” CPU ê°•ì œ ì‚¬ìš©
            model_kwargs={"low_cpu_mem_usage": True} # ë©”ëª¨ë¦¬ ì ìœ  ìµœì†Œí™”
        )
    except Exception as e:
        st.warning(f"âš ï¸ Reranker(TinyBERT) ë¡œë“œ ì‹¤íŒ¨: {e}. ê¸°ë³¸ ê²€ìƒ‰ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
        reranker = None 

    return hybrid_retriever, reranker

with st.spinner("ğŸš€ AI 5ë‹¨ê³„ ì‹¬ì¸µ ê²€ìƒ‰ ì—”ì§„ ì‹œë™ ì¤‘..."):
    try:
        hybrid_retriever, reranker_model = load_search_system()
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ë¡œë”© ì‹¤íŒ¨: {e}")
        st.stop()

# LLM ì´ˆê¸°í™”
safety_settings = {HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE}
llm_text = ChatGoogleGenerativeAI(model=MODEL_NAME, temperature=0.1, google_api_key=GOOGLE_API_KEY, safety_settings=safety_settings)
llm_vision = ChatGoogleGenerativeAI(model=MODEL_NAME, temperature=0, google_api_key=GOOGLE_API_KEY, safety_settings=safety_settings)

# ==========================================================
# [2] Deep RAG íŒŒì´í”„ë¼ì¸ (5ë‹¨ê³„ ë¡œì§ êµ¬í˜„)
# ==========================================================

# (1) ì¿¼ë¦¬ í™•ì¥ (Query Expansion)
expansion_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ê±´ì„¤/ê±´ì¶• ê²€ìƒ‰ ìµœì í™” AIì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆëŠ” **'í™•ì¥ ê²€ìƒ‰ì–´'** 3ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.
ê±´ì„¤ í‘œì¤€ ì‹œë°©ì„œ, ë²•ê·œ ìš©ì–´, ë™ì˜ì–´ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

[ì‚¬ìš©ì ì§ˆë¬¸]: {question}

[ì¶œë ¥ í˜•ì‹]: ì§ˆë¬¸ | í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3
(ì„¤ëª… ì—†ì´ ìœ„ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”)
""")
expansion_chain = expansion_prompt | llm_text | StrOutputParser()

def get_expanded_queries(original_query):
    """(1ë‹¨ê³„) ì‚¬ìš©ì ì§ˆë¬¸ì„ í™•ì¥í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    try:
        expanded_str = expansion_chain.invoke({"question": original_query})
        if "|" in expanded_str:
            base, keywords = expanded_str.split("|", 1)
            queries = [base.strip()] + [k.strip() for k in keywords.split(",")]
        else:
            queries = [original_query]
        return queries[:4] # ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ ì‚¬ìš© (ì†ë„ ì¡°ì ˆ)
    except:
        return [original_query]

# (2)~(4) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + ì¬ìˆœìœ„í™” + Top-K í•„í„°ë§
def retrieve_and_rerank(query, top_k=50):
    # Step 1: ì¿¼ë¦¬ í™•ì¥
    expanded_queries = get_expanded_queries(query)
    
    # Step 2: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í™•ì¥ëœ ì¿¼ë¦¬ ê°ê° ìˆ˜í–‰)
    all_docs = []
    seen_contents = set()
    
    for q in expanded_queries:
        docs = hybrid_retriever.invoke(q)
        for doc in docs:
            if doc.page_content not in seen_contents:
                all_docs.append(doc)
                seen_contents.add(doc.page_content)
    
    if not all_docs: return []

    # --- [ìˆ˜ì • êµ¬ê°„] Rerankerê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ ì¥ì¹˜ ---
    # reranker_modelì´ Noneì´ë©´ ì •ë°€ ì¬ìˆœìœ„í™” ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ê³  ë°”ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    if reranker_model is None:
        return all_docs[:top_k]

    # Step 3: ì •ë°€ ì¬ìˆœìœ„í™” (Cross-Encoder)
    pairs = [[query, doc.page_content] for doc in all_docs]
    scores = []
    batch_size = 16 # ë©”ëª¨ë¦¬ í™•ë³´ë¥¼ ìœ„í•´ ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì„ (ê¸°ì¡´ 32)
    
    try:
        for i in range(0, len(pairs), batch_size):
            batch = pairs[i : i + batch_size]
            batch_scores = reranker_model.predict(batch)
            scores.extend(batch_scores)
        
        scored_docs = sorted(zip(all_docs, scores), key=lambda x: x[1], reverse=True)
        # Step 4: Top-K í•„í„°ë§
        final_top_k = [doc for doc, score in scored_docs[:top_k]]
    except Exception as e:
        st.error(f"Reranking ê³¼ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return all_docs[:top_k]
        
    return final_top_k

# (5) ë‹µë³€ ìƒì„± (ìœ ì—°í•œ í”„ë¡¬í”„íŠ¸)
spacing_chain = ChatPromptTemplate.from_template("êµì •ëœ í•œêµ­ì–´ ë¬¸ì¥ë§Œ ì¶œë ¥(ì„¤ëª…X): {question}").pipe(llm_text).pipe(StrOutputParser())

answer_prompt = ChatPromptTemplate.from_messages([
    ("system", """
    ë‹¹ì‹ ì€ ë² í…Œë‘ ê±´ì„¤ ì‚¬ì—… ê´€ë¦¬ì(CM)ì´ì ì‹œê³µ ê¸°ìˆ ì‚¬ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ [Context](ê²€ìƒ‰ëœ ë²•ê·œ/ì‹œë°©ì„œ)ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

    [ë‹µë³€ ê·œì¹™]
    1. **ìš°ì„  ìˆœìœ„:** [Context]ì— êµ¬ì²´ì ì¸ ì ˆì°¨ë‚˜ ê¸°ì¤€ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ê·¸ê²ƒì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    2. **ì¼ë°˜ ì§€ì‹ í™œìš©:** ë§Œì•½ [Context]ì— 'í•´ê²° ë°©ì•ˆ'ì´ë‚˜ 'êµ¬ì²´ì  ê³µë²•'ì´ ë¶€ì¡±í•˜ë‹¤ë©´, 
       **"ì œê³µëœ ë²•ê·œ ë°ì´í„°ì—ëŠ” êµ¬ì²´ì  ë°©ë²•ì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ìœ¼ë‚˜, ì¼ë°˜ì ì¸ ì‹œê³µ ê¸°ì¤€ì— ë”°ë¥´ë©´..."** ì´ë¼ê³  ì–¸ê¸‰í•œ ë’¤, ë‹¹ì‹ ì´ ì•Œê³  ìˆëŠ” **í‘œì¤€ ì‹œë°©ì„œ ë° ê³µí•™ì  ì§€ì‹**ì„ ë™ì›í•´ í•´ê²°ì±…ì„ ì œì‹œí•˜ì„¸ìš”.
    3. ì ˆëŒ€ "ëª¨ë¥¸ë‹¤"ê³  ëë‚´ì§€ ë§ê³ , ì‹¤ë¬´ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
    4. ì¶œì²˜ê°€ ìˆë‹¤ë©´ [ì¶œì²˜: ...] í˜•íƒœë¡œ ëª…ì‹œí•˜ì„¸ìš”.

    [Context]
    {context}
    """),
    ("human", "ì§ˆë¬¸: {question}")
])

def format_docs(docs):
    return "\n\n".join([f"<ì¶œì²˜: {d.metadata.get('source')} / {d.metadata.get('article')}>\n{d.page_content}" for d in docs])

# ìµœì¢… RAG ì²´ì¸ (Top-50 ì ìš©)
rag_chain = (
    {"context": RunnableLambda(lambda x: retrieve_and_rerank(x, top_k=50)) | format_docs, "question": RunnablePassthrough()}
    | answer_prompt | llm_text | StrOutputParser()
)

# ==========================================================
# [3] Vision AI (ë„ë©´ ë¶„ì„ìš©)
# ==========================================================
def analyze_page_detail(image_base64, query, retrieved_docs):
    # ê²€ìƒ‰ëœ ë²•ê·œ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    laws_context = "\n".join([f"[{d.metadata.get('source')}] {d.page_content}" for d in retrieved_docs])
    
    if not laws_context.strip():
        laws_context = "ê´€ë ¨ëœ êµ¬ì²´ì  ë²•ê·œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ ê¸°ìˆ  ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”."

    # [ìˆ˜ì • ë°©í–¥] ì‚¬ìš©ìê»˜ì„œ ì£¼ì‹  ì§€ì¹¨ì„ ë³€ìˆ˜ë¡œ ê³ ì •í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ê°•ì œ ì£¼ì…
    structural_guideline = """
    [ìµœìš°ì„  ê´€ë¦¬ í•­ëª©: êµ¬ì¡° ì•ˆì „ì„± ë° ë³´ê°• ê³µë²• ê²€í†  ì§€ì¹¨]
    1. êµ¬ì¡° ì•ˆì „ì„± ë° ë³´ê°• ê³µë²• ê²€í†  (ìµœìš°ì„  ê´€ë¦¬ í•­ëª©)
       - ë³¸ í”„ë¡œì íŠ¸ëŠ” ë…¸í›„ ê±´ë¬¼(1974ë…„ ì¤€ê³µ) ìƒë¶€ì— 1ê°œ ì¸µì„ ìˆ˜ì§ ì¦ì¶•í•˜ê³  3ê°œ ë™ì„ ì—°ê²°í•˜ëŠ” ê³ ë‚œë„ ê³µì‚¬ì„.
    2. ê¸°ì¡´ êµ¬ì¡°ë¬¼ ìƒíƒœ í‰ê°€ ë° ë³´ê°• ì„ í›„í–‰ ê´€ë¦¬:
       - ì² ê±° ê³µì‚¬ ì°©ìˆ˜ ì „, ê¸°ì¡´ ìŠ¬ë˜ë¸Œ, ë³´, ê¸°ë‘¥ì˜ ê· ì—´, ì²˜ì§, ë‚´ë ¥ ì €í•˜ ì—¬ë¶€ ì ê²€ ë° ì¤€ê³µ ë„ë©´ ì¼ì¹˜ ì—¬ë¶€ ë³´ê³  í™•ì¸.
       - ì¦ì¶• ê³µì‚¬(ì² ê³¨ ì„¸ìš°ê¸°) ì „, í•˜ë¶€ êµ¬ì¡°ë¬¼ì˜ ì—°ì§ ë³´ê°•(ë‹¨ë©´ ì¦íƒ€, ì² íŒ ë³´ê°•) ë° ë‚´ì§„ ë³´ê°•(íƒ„ì†Œì„¬ìœ  ë³´ê°•) ì™„ë£Œ ì—¬ë¶€ í™•ì¸.
    3. ì£¼ìš” ë³´ê°• ê³µë²•ì— ëŒ€í•œ ì ì •ì„± ê²€í† :
       - ê¸°ë‘¥/ë³´ ë³´ê°•: ê¸°ë‘¥ ë‹¨ë©´ ì¦íƒ€ ë° ì² íŒ ì••ì°© ë³´ê°•(SV-401) ì‹œê³µ ì‹œ, ê¸°ì¡´ ì½˜í¬ë¦¬íŠ¸ ë©´ì˜ ì¹˜í•‘(Chipping) ìƒíƒœì™€ ì‹ êµ¬ ì ‘ì°©ì œ ì„±ëŠ¥, ë¬´ìˆ˜ì¶• ëª°íƒˆì˜ ì¶©ì „ ë°€ì‹¤ë„ ê²€ì¦.
       - ìŠ¬ë˜ë¸Œ íƒ„ì†Œì„¬ìœ  ë³´ê°•: íƒ„ì†Œì„¬ìœ  ì‹œíŠ¸(SK-N600 ë“±) ë¶€ì°© ì‹œ, ë°”íƒ•ë©´ ì²˜ë¦¬ ìƒíƒœ(í‰í™œë„)ì™€ í”„ë¼ì´ë¨¸ ë„í¬ ì ì •ì„±, ë¶€ì°© ê°•ë„ ì‹œí—˜(Pull-off test) ê³„íš ìˆ˜ë¦½ ì—¬ë¶€.
    4. ì‹ êµ¬ ì ‘í•©ë¶€ ë° ì´ì§ˆ ì¬ë£Œ ì—°ê²° ìƒì„¸:
       - ê¸°ì¡´ RC ê¸°ë‘¥ ìƒë¶€ ì‹ ì„¤ ì² ê³¨ ê¸°ë‘¥(SC1, SC2 ë“±) ì •ì°©ìš© ë² ì´ìŠ¤ í”Œë ˆì´íŠ¸ ë° ì¼€ë¯¸ì»¬ ì•µì»¤(Hilti RE500 ë“±) ì¸ë°œ ë‚´ë ¥ ì‹œí—˜ ì„±ì ì„œ í™•ì¸ ë° ê°„ì„­ ê²€í† .
       - ì² ê³¨ë³´(H-Beam)ì™€ ê¸°ì¡´ ì½˜í¬ë¦¬íŠ¸ ë³´ ì—°ê²° ë¶€ìœ„ ì „ë‹¨ ì ‘í•© ìƒì„¸(Shear Connection) ì‹œê³µì„± ê²€í† .
    """

    prompt_text = f"""
        ë‹¹ì‹ ì€ ë² í…Œë‘ ê±´ì„¤ ì‚¬ì—… ê´€ë¦¬ì(CM)ì´ì ì‹œê³µ ê¸°ìˆ ì‚¬ì…ë‹ˆë‹¤. 
        ë‹¹ì‹ ì˜ ìµœìš°ì„  ì„ë¬´ëŠ” ì œê³µëœ **[êµ¬ì¡° ì•ˆì „ ì§€ì¹¨]**ê³¼ ë„ë©´ì„ ëŒ€ì¡°í•˜ì—¬ íŒ©íŠ¸ ì¤‘ì‹¬ì˜ ê²€í†  ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
        
        [ì§ˆë¬¸/ê²€í†  ìš”ì²­]: {query}
        
        {structural_guideline}
        
        [ì°¸ê³  ë²•ê·œ/ê¸°ì¤€(DB)]:
        {laws_context}
        
        [ë¶„ì„ ì§€ì¹¨]:
        1. **ì§€ì¹¨ ê¸°ë°˜ í•„í„°ë§:** ë„ë©´ ë¶„ì„ ì‹œ ë°˜ë“œì‹œ ìœ„ 1~4ë²ˆ ì§€ì¹¨ì„ ê¸°ì¤€ìœ¼ë¡œ ìœ„ë°˜ ì‚¬í•­ì´ë‚˜ ëˆ„ë½ ì‚¬í•­ì„ ì°¾ìœ¼ì‹­ì‹œì˜¤.
        2. **ìˆ˜ë¦¬ì  íŒ©íŠ¸ ì²´í¬:** ì•µì»¤ì˜ ì •ì°© ê¹Šì´, ë³´ê°• ë‘ê»˜, EL/FL ê°’ ë“±ì„ ë„ë©´ì—ì„œ ì°¾ì•„ ê³„ì‚°ì‹ì„ ëª…ì‹œí•˜ì‹­ì‹œì˜¤.
        3. **ìƒì„¸ë„ ê²€í† :** SC1, SC2 ë“± ì‹ ì„¤ ê¸°ë‘¥ê³¼ ê¸°ì¡´ RC ê¸°ë‘¥ì˜ ì ‘í•©ë¶€(Base Plate) ìƒì„¸ê°€ ì§€ì¹¨(Hilti RE500 ë“±)ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.

        [ë‹µë³€ êµ¬ì¡°]:
        - **ì¤‘ëŒ€ ìœ„ë°˜/ìœ„í—˜ í•­ëª© (êµ¬ì¡° ë³´ê°• íŠ¹í™”):**
            * **[ê·¼ê±°]:** (ìœ„ ì§€ì¹¨ ì¤‘ í•´ë‹¹ í•­ëª© ë²ˆí˜¸ ëª…ì‹œ)
            * í˜„í™©: (ë„ë©´ ìœ„ì¹˜ ë° í™•ì¸ëœ ìˆ˜ì¹˜/í‘œê¸°)
            * ë¬¸ì œì : (ì§€ì¹¨ ëŒ€ë¹„ ë¯¸í¡í•œ ì ì´ë‚˜ ì˜ˆìƒë˜ëŠ” êµ¬ì¡°ì  ê²°í•¨)
            * ê°œì„ ì•ˆ: (êµ¬ì²´ì  ë³´ê°• ê³µë²•ì´ë‚˜ ì‹œê³µ ì‹œ ë³´ì™„ ëŒ€ì±…)
        - **ê¸°ìˆ ì  ì œì–¸:** êµ¬ì¡° ì™¸ì— ì‹œê³µ ì „ë¬¸ê°€ë¡œì„œ ì œì–¸í•˜ëŠ” ì‚¬í•­
        """
    
    message = HumanMessage(content=[
        {"type": "text", "text": prompt_text},
        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}},
    ])
    
    try:
        response = llm_vision.invoke([message])
        return response.content
    except Exception as e:
        return f"ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ: {e}"

def generate_final_report(file_name, page_results):
    raw_data = ""
    for item in page_results:
        raw_data += f"\n[Page {item['page']}]: {item['content']}\n"
    
    current_date = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    
    # ë³´ê³ ì„œ ìƒì„± ì‹œì—ë„ 1974ë…„ ë…¸í›„ ê±´ë¬¼ ì¦ì¶•ì´ë¼ëŠ” ë§¥ë½ì„ ìœ ì§€í•˜ê²Œ í•¨
    prompt = f"""
    ë‹¹ì‹ ì€ ê±´ì„¤ì‚¬ì—…ê´€ë¦¬ë‹¨ì¥(CMë‹¨ì¥)ì…ë‹ˆë‹¤. 
    1974ë…„ ì¤€ê³µ ë…¸í›„ ê±´ë¬¼ì˜ ìˆ˜ì§ ì¦ì¶• ë° ë³´ê°• ê³µì‚¬ë¼ëŠ” íŠ¹ìˆ˜ì„±ì„ ê³ ë ¤í•˜ì—¬ 'ìµœì¢… ì‹œê³µ í’ˆì§ˆ/ì•ˆì „ ê²€í†  ë³´ê³ ì„œ'ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    [ì‘ì„± ê°€ì´ë“œ]
    - 'êµ¬ì¡° ì•ˆì „ì„± í™•ë³´'ì™€ 'ë³´ê°• ê³µë²•ì˜ ì‹¤ë¬´ì  ì ì •ì„±'ì„ ê°€ì¥ ê°•ì¡°í•˜ì‹­ì‹œì˜¤.
    - í”„ë¡œì íŠ¸ëª…ì€ ë³„ë„ ì–¸ê¸‰ ì—†ìœ¼ë©´ '{file_name}'ìœ¼ë¡œ ê¸°ì¬í•˜ì„¸ìš”.

    [ë¶„ì„ ë°ì´í„°]
    {raw_data}
    
    [ë³´ê³ ì„œ í˜•ì‹]
    1. ë„ë©´ëª…: {file_name}
    2. ì‘ì„± ì¼ì: {current_date}
    3. ì‘ì„±ì: AI ê±´ì„¤ ì§€ì› ì‹œìŠ¤í…œ (êµ¬ì¡° ì•ˆì „ íŠ¹í™”)
    4. ê²€í†  ì´í‰: (ë…¸í›„ ê±´ì¶•ë¬¼ ì¦ì¶•ì— ë”°ë¥¸ êµ¬ì¡°ì  ë¦¬ìŠ¤í¬ì™€ ë³´ê°• ëŒ€ì±… ìš”ì•½)
    5. ì£¼ìš” ê²€í†  ë‚´ìš© (í•­ëª©ë³„ ìš”ì•½): ...
    """
    return llm_text.invoke(prompt).content


    """
    AIê°€ ì‘ì„±í•œ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ë§¥í‚¨ì§€ ìŠ¤íƒ€ì¼ì˜ ì—‘ì…€ ë°ì´í„°ë¡œ ë³€í™˜
    """
    # AIì—ê²Œ ì—‘ì…€ìš© í‘œ ë°ì´í„°ë¥¼ ë”°ë¡œ ì¶”ì¶œí•˜ë„ë¡ ìš”ì²­
    excel_prompt = f"""


    [ì¶œë ¥ ê·œì¹™]
    - ë°˜ë“œì‹œ 'ë„ë©´ì •ë³´ | í˜„í™© | ë¬¸ì œì  | ê°œì„ ì•ˆ | ì²´í¬ì—¬ë¶€' í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
    - êµ¬ë¶„ì '|'ë¥¼ ì‚¬ìš©í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ ì¼ì ˆ ìƒëµí•˜ì„¸ìš”.

    [ë³´ê³ ì„œ ë‚´ìš©]
    {report_content}
    """
    
    try:
        raw_data = llm_text.invoke(excel_prompt).content
        rows = []
        for line in raw_data.split('\n'):
            if '|' in line and 'ë„ë©´ì •ë³´' not in line: # í—¤ë” ì œì™¸ ë°ì´í„°ë§Œ
                rows.append([item.strip() for item in line.split('|')])
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame(rows, columns=['ë„ë©´ì •ë³´', 'í˜„í™©', 'ë¬¸ì œì ', 'ê°œì„ ì•ˆ', 'ì²´í¬ì—¬ë¶€'])
        
        # ì—‘ì…€ íŒŒì¼ ìƒì„± (ë©”ëª¨ë¦¬ ë²„í¼)
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False, sheet_name='ë„ë©´ê²€í† ì²´í¬ë¦¬ìŠ¤íŠ¸')
            
            workbook  = writer.book
            worksheet = writer.sheets['ë„ë©´ê²€í† ì²´í¬ë¦¬ìŠ¤íŠ¸']

            # ë§¥í‚¨ì§€ ìŠ¤íƒ€ì¼ ì„œì‹ (ë‚¨ìƒ‰ í—¤ë”, í°ìƒ‰ ê¸€ì, ë§‘ì€ ê³ ë”•)
            header_format = workbook.add_format({
                'bold': True, 'font_name': 'ë§‘ì€ ê³ ë”•', 'font_size': 11,
                'bg_color': '#003366', 'font_color': 'white',
                'border': 1, 'align': 'center', 'valign': 'vcenter'
            })
            body_format = workbook.add_format({
                'font_name': 'ë§‘ì€ ê³ ë”•', 'font_size': 10,
                'border': 1, 'valign': 'vcenter', 'text_wrap': True
            })

            # ì„œì‹ ì ìš© ë° ì—´ ë„ˆë¹„ ì¡°ì •
            for col_num, value in enumerate(df.columns.values):
                worksheet.write(0, col_num, value, header_format)
                worksheet.set_column(col_num, col_num, 30, body_format)
            
            worksheet.set_row(0, 25) # í—¤ë” ë†’ì´

        return output.getvalue()
    except:
        return None
    
def create_excel_report(report_content):
    """
    ìµœì¢… ìˆ˜ì •: B2 ì‹œì‘, ì¼ì •í•œ í–‰ ë†’ì´, ë„ë©´ì •ë³´ ì¤„ë°”ê¿ˆ ë° ìš”ì•½ ì ìš©
    """
    excel_prompt = f"""
    ë‹¹ì‹ ì€ ê±´ì„¤ ë°ì´í„° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ [ë³´ê³ ì„œ ë‚´ìš©]ì„ ë°”íƒ•ìœ¼ë¡œ í˜„ì¥ ê¸°ìˆ ììš© ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“œì„¸ìš”.

    [ì‘ì„± ê·œì¹™]
    1. ë„ë©´ ì •ë³´(í˜ì´ì§€): 'íŒŒì¼ëª….pdf'ì™€ '(í˜ì´ì§€/ë¶€ìœ„)' ì‚¬ì´ì— ë°˜ë“œì‹œ 'NL'ì´ë¼ëŠ” ê¸€ìë¥¼ ë„£ì–´ êµ¬ë¶„í•˜ì„¸ìš”.
    2. í˜„í™© ë° ë¬¸ì œì  / ê°œì„ ì•ˆ(ë³´ì™„ëŒ€ì±…): í•µì‹¬ í‚¤ì›Œë“œ ì¤‘ì‹¬ìœ¼ë¡œ ì•„ì£¼ ê°„ê²°í•˜ê²Œ 'ìš”ì•½'í•´ì„œ ì‘ì„±í•˜ì„¸ìš”.
    
    [í‘œ êµ¬ì„± ë° ì¶œë ¥ í˜•ì‹]
    í˜•ì‹: ë„ë©´ ì •ë³´(í˜ì´ì§€) | í˜„í™© ë° ë¬¸ì œì  | ê°œì„ ì•ˆ(ë³´ì™„ëŒ€ì±…) | ì²´í¬
    êµ¬ë¶„ì '|'ë¥¼ ì‚¬ìš©í•˜ê³  ë°ì´í„°ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

    [ë³´ê³ ì„œ ë‚´ìš©]
    {report_content}
    """
    
    try:
        raw_data = llm_text.invoke(excel_prompt).content
        rows = []
        for line in raw_data.split('\n'):
            if '|' in line and 'ë„ë©´ ì •ë³´' not in line:
                parts = [item.strip() for item in line.split('|')]
                if len(parts) >= 3:
                    drawing_info = parts[0].replace("NL", "\n")
                    rows.append([drawing_info, parts[1], parts[2], "â–¡ ë¯¸í™•ì¸"])
        
        df = pd.DataFrame(rows, columns=['ë„ë©´ ì •ë³´(í˜ì´ì§€)', 'í˜„í™© ë° ë¬¸ì œì ', 'ê°œì„ ì•ˆ(ë³´ì™„ëŒ€ì±…)', 'ì²´í¬'])
        output = BytesIO()
        
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            # [ìˆ˜ì •] B2 ì…€ë¶€í„° ì‹œì‘í•˜ë„ë¡ startrow=1, startcol=1 ì„¤ì •
            df.to_excel(writer, index=False, sheet_name='ê²€í† ì²´í¬ë¦¬ìŠ¤íŠ¸', startrow=1, startcol=1)
            
            workbook  = writer.book
            worksheet = writer.sheets['ê²€í† ì²´í¬ë¦¬ìŠ¤íŠ¸']

            # ì„œì‹ ì •ì˜
            header_fmt = workbook.add_format({
                'bold': True, 'font_name': 'ë§‘ì€ ê³ ë”•', 'font_size': 11,
                'bg_color': '#003366', 'font_color': 'white', 'border': 1, 'align': 'center', 'valign': 'vcenter'
            })
            
            center_bold_fmt = workbook.add_format({
                'bold': True, 'font_name': 'ë§‘ì€ ê³ ë”•', 'font_size': 10, 'border': 1,
                'align': 'center', 'valign': 'vcenter', 'text_wrap': True
            })
            center_bold_gray_fmt = workbook.add_format({
                'bold': True, 'font_name': 'ë§‘ì€ ê³ ë”•', 'font_size': 10, 'border': 1,
                'align': 'center', 'valign': 'vcenter', 'text_wrap': True, 'bg_color': '#F2F5F9'
            })
            
            left_vcenter_fmt = workbook.add_format({
                'font_name': 'ë§‘ì€ ê³ ë”•', 'font_size': 10, 'border': 1,
                'align': 'left', 'valign': 'vcenter', 'text_wrap': True
            })
            left_vcenter_gray_fmt = workbook.add_format({
                'font_name': 'ë§‘ì€ ê³ ë”•', 'font_size': 10, 'border': 1,
                'align': 'left', 'valign': 'vcenter', 'text_wrap': True, 'bg_color': '#F2F5F9'
            })

            # ì—´ ë„ˆë¹„ ì„¤ì • (Bì—´ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ Aì—´ì€ ë¹„ì›Œë‘ )
            worksheet.set_column('A:A', 3)   # ì™¼ìª½ ì—¬ë°±
            worksheet.set_column('B:B', 22)  # ë„ë©´ ì •ë³´
            worksheet.set_column('C:C', 45)  # í˜„í™© ë° ë¬¸ì œì 
            worksheet.set_column('D:D', 50)  # ê°œì„ ì•ˆ
            worksheet.set_column('E:E', 12)  # ì²´í¬

            # [ìˆ˜ì •] ë°ì´í„° ì“°ê¸° ë° í–‰ ë†’ì´ í†µì¼
            # ê³ ì • í–‰ ë†’ì´ ì„¤ì • (ê°€ë…ì„±ì„ ìœ„í•´ 45~50 ì •ë„ê°€ ì ë‹¹í•©ë‹ˆë‹¤)
            row_height = 45 
            
            for row_num, data in enumerate(rows):
                is_even = row_num % 2 == 1
                r_idx = row_num + 2 # B2ê°€ í—¤ë”ì´ë¯€ë¡œ ë°ì´í„°ëŠ” 3í–‰(index 2)ë¶€í„° ì‹œì‘
                
                # í–‰ ë†’ì´ ì¼ì •í•˜ê²Œ ê³ ì •
                worksheet.set_row(r_idx, row_height)
                
                fmt_center = center_bold_gray_fmt if is_even else center_bold_fmt
                fmt_left = left_vcenter_gray_fmt if is_even else left_vcenter_fmt
                
                # ì—´ ìœ„ì¹˜ë¥¼ í•˜ë‚˜ì”© ë°€ì–´ì„œ(1, 2, 3, 4) ì‘ì„±
                worksheet.write(r_idx, 1, data[0], fmt_center) # Bì—´
                worksheet.write(r_idx, 2, data[1], fmt_left)   # Cì—´
                worksheet.write(r_idx, 3, data[2], fmt_left)   # Dì—´
                worksheet.write(r_idx, 4, data[3], fmt_center) # Eì—´

            # í—¤ë” ë‹¤ì‹œ ì“°ê¸° (B2 ì…€ë¶€í„°)
            worksheet.set_row(1, 32) # í—¤ë” í–‰ ë†’ì´
            for col_num, value in enumerate(df.columns.values):
                worksheet.write(1, col_num + 1, value, header_fmt)
            
            # ë“œë¡­ë°•ìŠ¤ ìœ„ì¹˜ ì¡°ì • (Eì—´)
            worksheet.data_validation(2, 4, len(df)+1, 4, {'validate': 'list', 'source': ['â–¡ ë¯¸í™•ì¸', 'âœ… í™•ì¸ì™„ë£Œ']})
            worksheet.freeze_panes(2, 0) # 2í–‰ê¹Œì§€ ê³ ì • (B2 í—¤ë” ë³´ì´ê²Œ)

        return output.getvalue()
    except Exception as e:
        st.error(f"Excel ìƒì„± ì˜¤ë¥˜: {e}")
        return None
    
# ==========================================================
# [4] ì›¹ UI (Streamlit)
# ==========================================================
st.title("ğŸ—ï¸ ê±´ì„¤ CM ì „ë¬¸ AI (Deep RAG + Vision)")

# ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processed_files" not in st.session_state:
    st.session_state.processed_files = set()
if "current_image_base64" not in st.session_state:
    st.session_state.current_image_base64 = None

# --- [ì‚¬ì´ë“œë°”] ìˆ˜ì • ë¶€ë¶„ ---
with st.sidebar:
    st.header("ğŸ“‚ ë„ë©´ íˆ¬ì…êµ¬")
    uploaded_files = st.file_uploader("PDF ë„ë©´ ì—…ë¡œë“œ", type=["pdf"], accept_multiple_files=True)
    
    st.markdown("---")
    
    # 3ê°€ì§€ ëª…í™•í•œ ëª¨ë“œ ì •ì˜
    mode_options = ["âš–ï¸ ë²•ê·œ DB ê²€ìƒ‰", "ğŸ’¬ ìˆœìˆ˜ Gemini ì§€ì‹"]
    if uploaded_files or st.session_state.current_image_base64:
        mode_options.insert(0, "ğŸ“‚ ë„ë©´ ê¸°ë°˜ ì§ˆë¬¸")

    st.subheader("ğŸ¤– ì§ˆë¬¸ ëª¨ë“œ")
    search_mode = st.radio("ëª¨ë“œ ì„ íƒ", mode_options, index=0)

    # ëŒ€í™” ì‚­ì œ ë²„íŠ¼ (íŒŒì¼ê¹Œì§€ ì‚­ì œ)
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        if os.path.exists(HISTORY_FILE):
            os.remove(HISTORY_FILE)
        st.rerun()


        
# --- [ë©”ì¸] ë„ë©´ ì²˜ë¦¬ ë¡œì§ (1ë²ˆ ë°©ë²• ì ìš© ìˆ˜ì •ë³¸) ---
if uploaded_files:
    for target_file in uploaded_files:
        if target_file.name not in st.session_state.processed_files:
            with st.status(f"ğŸ“„ '{target_file.name}' ë¶„ì„ ì¤‘...", expanded=True) as status:
                # 1. ì„ì‹œ íŒŒì¼ ì €ì¥
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                    tmp_file.write(target_file.read())
                    tmp_path = tmp_file.name 
                
                try:
                    # [ìˆ˜ì •ëœ ë¶€ë¶„] pdf_info_to_dict ëŒ€ì‹  pdfinfo_from_path ì‚¬ìš©
                    from pdf2image import pdfinfo_from_path
                    
                    # PDF ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    info = pdfinfo_from_path(tmp_path, poppler_path=POPPLER_PATH)
                    total_pages = info["Pages"] # í˜ì´ì§€ ìˆ˜ ì¶”ì¶œ
                    
                    page_results = []
                    progress = st.progress(0)

                    # 2. Vision ë¶„ì„ ë£¨í”„
                    for i in range(total_pages):
                        curr_page = i + 1
                        progress.progress(curr_page / total_pages, text=f"ğŸ” {curr_page}/{total_pages} í˜ì´ì§€ ì •ë°€ ì§„ë‹¨ ì¤‘...")
                        
                        # [í•µì‹¬] í•´ë‹¹ í˜ì´ì§€ë§Œ ë©”ëª¨ë¦¬ì— ë¡œë“œ + í•´ìƒë„ ì¡°ì ˆ(size)ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
                        # size=(1200, None)ì€ ê°€ë¡œë¥¼ 1200pxë¡œ ë§ì¶”ê³  ì„¸ë¡œëŠ” ë¹„ìœ¨ì— ë§ê²Œ ì¡°ì •í•©ë‹ˆë‹¤.
                        page_images = convert_from_path(
                            tmp_path, 
                            first_page=curr_page, 
                            last_page=curr_page,
                            size=(1200, None), 
                            poppler_path=POPPLER_PATH
                        )
                        
                        if not page_images:
                            continue
                         
                        page_img = page_images[0]
                        
                        # ì´ë¯¸ì§€ base64 ë³€í™˜
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_img:
                            # qualityë¥¼ 75~80ìœ¼ë¡œ ë‚®ì¶”ë©´ ë©”ëª¨ë¦¬ ì ìœ ìœ¨ì´ ë” ë‚´ë ¤ê°‘ë‹ˆë‹¤.
                            page_img.save(tmp_img.name, "JPEG", quality=80)
                            with open(tmp_img.name, "rb") as f:
                                img_base64 = base64.b64encode(f.read()).decode("utf-8")
                        
                        st.session_state.current_image_base64 = img_base64 # ìµœì‹  ì´ë¯¸ì§€ ìœ ì§€
                        
                        # ë¶„ì„ ì‹¤í–‰
                        res = analyze_page_detail(img_base64, "ìœ„í—˜ ìš”ì†Œ ì‹ë³„", [])
                        page_results.append({"page": curr_page, "content": res})
                        
                        # [í•µì‹¬] ë©”ëª¨ë¦¬ ê°•ì œ í•´ì œ
                        # ë³€ìˆ˜ ì°¸ì¡°ë¥¼ ì œê±°í•˜ê³  ê°€ë¹„ì§€ ì»¬ë ‰í„°ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
                        del page_img
                        del page_images
                        gc.collect() 

                except Exception as e:
                    st.error(f"ë³€í™˜/ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    continue
                finally:
                    # ë¶„ì„ ì™„ë£Œ í›„ ì„ì‹œ PDF íŒŒì¼ ì‚­ì œ ì‹œë„
                    if os.path.exists(tmp_path):
                        try: os.remove(tmp_path)
                        except: pass
                
                # 3. ì¢…í•© ë³´ê³ ì„œ ì‘ì„± ë° íŒŒì¼ë³„ ì—‘ì…€ ìƒì„±
                status.write("ğŸ“ ì¢…í•© ë³´ê³ ì„œ ì‘ì„± ì¤‘...")
                report = generate_final_report(target_file.name, page_results)
                current_excel_data = create_excel_report(report)

                st.session_state.processed_files.add(target_file.name)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": report,
                    "excel_data": current_excel_data,
                    "file_name": target_file.name
                })

                progress.empty()
                status.update(label="âœ… ë¶„ì„ ì™„ë£Œ", state="complete")


# --- [ì±„íŒ…ì°½ ì˜ì—­ í•˜ë‹¨ ìˆ˜ì •] ---
for idx, msg in enumerate(st.session_state.messages):
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        
        # [ìˆ˜ì •] ë©”ì‹œì§€ ì•ˆì— ì—‘ì…€ ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” ê²½ìš°ì—ë§Œ ë²„íŠ¼ ìƒì„±
        if msg.get("excel_data") is not None:
            st.download_button(
                label=f"ğŸ“¥ {msg['file_name']} ê²€í† ê²°ê³¼(ì—‘ì…€) ë‹¤ìš´ë¡œë“œ",
                data=msg["excel_data"],
                file_name=f"ê²€í† ê²°ê³¼_{msg['file_name']}_{datetime.now().strftime('%m%d')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key=f"btn_dl_{idx}" # ê³ ìœ  ID ë¶€ì—¬ë¡œ ì˜¤ë¥˜ í•´ê²°
            )

# --- [ë©”ì¸ ì±„íŒ… ì²˜ë¦¬ ë¡œì§] ---
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # 1. ì‚¬ìš©ì ì§ˆë¬¸ ê¸°ë¡
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # [Option 1] ë„ë©´ ê¸°ë°˜ ì§ˆë¬¸ (ë„ë©´ ì´ë¯¸ì§€ + DB ê²€ìƒ‰)
        if search_mode == "ğŸ“‚ ë„ë©´ ê¸°ë°˜ ì§ˆë¬¸":
            with st.status("ğŸ” ë„ë©´ ë° ë²•ê·œ êµì°¨ ë¶„ì„ ì¤‘..."):
                corrected_query = spacing_chain.invoke({"question": prompt})
                relevant_docs = retrieve_and_rerank(corrected_query, top_k=10) 
                response = analyze_page_detail(st.session_state.current_image_base64, prompt, relevant_docs)
        
        # [Option 2] ë²•ê·œ DB ê²€ìƒ‰ (RAG ì „ìš©)
        elif search_mode == "âš–ï¸ ë²•ê·œ DB ê²€ìƒ‰":
            with st.status("ğŸ§  DB ë‚´ ë²•ê·œ/ì‹œë°©ì„œ ê²€ìƒ‰ ì¤‘..."):
                response = rag_chain.invoke(prompt)

        # [Option 3] ìˆœìˆ˜ Gemini ì§€ì‹ (ë¬¸ë§¥ ìœ ì§€ - ì´ ë¶€ë¶„ì´ í¬ì¸íŠ¸!)
        else:
            with st.spinner("Geminiê°€ ëŒ€í™” ë‚´ì—­ì„ ì½ê³  ë‹µë³€ ì¤‘..."):
                # â˜… promptë§Œ ë³´ë‚´ëŠ” ê²Œ ì•„ë‹ˆë¼ ì „ì²´ messagesë¥¼ ë³´ëƒ…ë‹ˆë‹¤.
                # ì´ë¥¼ í†µí•´ ì•ì„œ ìƒì„±ëœ 'ë„ë©´ ë¶„ì„ ë³´ê³ ì„œ' ë‚´ìš©ì„ ì œë¯¸ë‚˜ì´ê°€ ì¸ì§€í•©ë‹ˆë‹¤.
                res_object = llm_text.invoke(st.session_state.messages)
                response = res_object.content

        # 2. ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
        st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})
        save_chat_history() # íŒŒì¼ì— ì¦‰ì‹œ ì˜êµ¬ ì €ì¥